Add your environment variables to run, it has two set of file one for open source ollama and one for openai. Open source one assumes you are running ollama on your local. 
Following environment keys you will have to get and put in environment (.env) file
#OPENAI_API_KEY=
LANGCHAIN_API_KEY=
PINECONE_API_KEY=
For running even llama3.1 you would need langchain and pinecone api key. These would be free to start with but you will have to sign up. 

